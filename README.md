# ğŸ›¡ï¸ MoMLDNIDS: Multi-Domain Network Intrusion Detection with Pseudo-Labeling and Clustering

[![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![CI](https://github.com/rafifmalikdzaki/DomainGeneralizationSkripsi/actions/workflows/ci.yml/badge.svg)](https://github.com/rafifmalikdzaki/DomainGeneralizationSkripsi/actions)
[![Weights & Biases](https://img.shields.io/badge/MLOps-Weights%20%26%20Biases-yellow.svg)](https://wandb.ai/)

## ğŸ”¬ Overview & Research Motivation

Network Intrusion Detection Systems (NIDS) face significant challenges when deploying across different network domains due to domain shift and limited labeled data availability. This project implements **MoMLDNIDS** (Multi-Domain Machine Learning Domain Network Intrusion Detection System), a cutting-edge research platform that addresses cross-domain NIDS deployment through:

ğŸ¯ **Core Innovations:**
- ğŸ”„ **Cross-Domain Adaptation**: Leveraging domain adversarial training with Gradient Reversal Layer (GRL) to learn domain-invariant features
- ğŸ·ï¸ **Pseudo-Labeling with Clustering**: Using unsupervised clustering to generate pseudo-domain labels for improved domain adaptation
- ğŸŒ **Multi-Domain Learning**: Training on multiple source domains to enhance generalization to unseen target domains
- ğŸ“Š **MLOps Integration**: Complete experiment tracking, configuration management, and explainable AI capabilities

âœ¨ **Modern ML Research Features:**
- ğŸ“ˆ **Experiment Tracking**: Weights & Biases integration for comprehensive metric logging (including ROC-AUC, PR curves, confusion matrices, and clustering metrics) and visualization
- âš¡ **Speed Optimizations**: Implemented mixed precision training, increased batch size, and optimized data loading with `num_workers` and `pin_memory` for faster training. for comprehensive experiment management
- âš™ï¸ **Configuration Management**: YAML-based configuration system with validation
- ğŸ” **Explainable AI**: Multiple interpretability methods (SHAP, LIME, Integrated Gradients)
- ğŸ”„ **Reproducible Research**: Automated environment management and deterministic training
- ğŸš€ **CI/CD Pipeline**: Automated testing and validation workflows

The core innovation lies in the combination of adversarial domain adaptation with clustering-based pseudo-labeling, enabling effective knowledge transfer between network domains while maintaining high intrusion detection accuracy.

## Architecture

The MoMLDNIDS architecture consists of three main components connected in a adversarial training framework:

```
Input Features (39D) 
       â†“
Feature Extractor (DGFeatExt)
  â”œâ”€ BatchNorm1d + ELU + Dropout layers
  â”œâ”€ Hidden layers: [64, 32, 16, 10]
  â””â”€ Invariant Features (10D)
       â†“
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â†“                     â†“
Label Classifier          Domain Discriminator
â”œâ”€ Classification         â”œâ”€ Domain prediction  
â”œâ”€ Output: [Benign,       â”œâ”€ Gradient Reversal Layer
â”‚   Attack]               â””â”€ Output: Cluster/Domain IDs
â””â”€ CrossEntropy Loss         â””â”€ CrossEntropy Loss
```

### Key Components:

1. **Feature Extractor**: Deep neural network with batch normalization and ELU activation
2. **Label Classifier**: Binary classification for intrusion detection (Benign/Attack)
3. **Domain Discriminator**: Multi-class classification for domain/cluster identification with GRL
4. **Clustering Module**: Mini-batch K-means for pseudo-domain label generation

## Datasets

The project utilizes three network flow datasets in Parquet format:

| Dataset | Description | Download Link | Records |
|---------|-------------|---------------|---------||
| **NF-UNSW-NB15-v2** | Network flows from UNSW-NB15 dataset | [UNSW-NB15](https://research.unsw.edu.au/projects/unsw-nb15-dataset) | ~2.5M |
| **NF-CSE-CIC-IDS2018-v2** | CIC-IDS2018 network flow dataset | [CIC-IDS2018](https://www.unb.ca/cic/datasets/ids-2018.html) | ~16M |
| **NF-ToN-IoT-v2** | IoT network traffic dataset | [ToN-IoT](https://research.unsw.edu.au/projects/toniot-datasets) | ~22M |

### Expected Data Directory Structure:
```
./data/parquet/
â”œâ”€â”€ NF-UNSW-NB15-v2/
â”‚   â”œâ”€â”€ *.parquet files
â”œâ”€â”€ NF-CSE-CIC-IDS2018-v2/
â”‚   â”œâ”€â”€ *.parquet files
â””â”€â”€ NF-ToN-IoT-v2/
    â”œâ”€â”€ *.parquet files
```

## Installation

### Prerequisites
- Python 3.9 or higher
- CUDA-capable GPU (recommended)
- 16GB+ RAM (for large datasets)

### Setup with uv (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd MoMLNIDS

# Create virtual environment using uv
uv venv .venv

# Activate virtual environment
source .venv/bin/activate  # On Linux/macOS
# .venv\Scripts\activate   # On Windows

# Install dependencies
uv pip install -r requirements.txt

# For GPU support, install CUDA version
uv pip install -r requirements-gpu.txt  # if available
```

### Alternative with pip

```bash
pip install -r requirements.txt
```

## ğŸš€ Usage Examples

### 1. ğŸ¯ Enhanced Training with MLOps

Run the improved training script with full configuration management and experiment tracking:

```bash
# Run with default configuration
python src/main_config.py

# Run with custom config file
python src/main_config.py --config config/custom_config.yaml

# Run quick test with minimal setup
python src/main_config.py --config config/quick_test_config.yaml
```

âœ¨ **Enhanced Features:**
- ğŸ“ˆ **Automatic Experiment Tracking**: Weights & Biases integration
- ğŸ” **Explainable AI**: Generate model interpretations automatically
- ğŸ’¾ **Model Versioning**: Save best models with metadata
- ğŸ”§ **Reproducible Results**: Deterministic training with seed management

### 2. ğŸ”„ Legacy Training Methods

#### Source-Only Baseline Training
```bash
python src/main.py
```

#### Pseudo-Label Clustering Sweep
```bash
python src/main_pseudo.py
```

#### Extended Training (50 Epochs)
```bash
python src/main_pseudo_50.py  # Verify file exists
```

### 3. âš™ï¸ Configuration Management

The enhanced system uses YAML configuration files for better parameter management:

```yaml
# config/default_config.yaml
project:
  name: "MoMLDNIDS"
  version: "2.0.0"
  description: "Multi-Domain NIDS with Enhanced MLOps"

model:
  feature_extractor:
    hidden_layers: [64, 32, 16, 10]
    dropout_rate: 0.3
    activation: "ELU"

training:
  epochs: 20
  batch_size: 1024
  learning_rate: 0.0015
  grl_weight: 1.25
  clustering_step: 2

wandb:
  enabled: true
  project: "nids-research"
  tags: ["domain-adaptation", "intrusion-detection"]
```

### 4. ğŸ” Explainable AI Usage

```python
from src.skripsi_code.explainability import ModelExplainer

# Initialize explainer
explainer = ModelExplainer(model, feature_names)

# Generate explanations
explanation = explainer.explain_instance(
    instance, 
    method="integrated_gradients"
)

# Visualize results
explainer.plot_feature_importance(explanation)
```

### 5. ğŸ§ª Environment Validation

Test your setup with the comprehensive validation script:

```bash
python tests/test_imports.py
```

This validates:
- âœ… Core dependencies
- âœ… Package imports
- âœ… Configuration loading
- âœ… Experiment tracking
- âœ… Explainability modules
- âœ… Optional dependencies (SHAP, LIME)

## ğŸ“ Project Structure

### ğŸš€ Enhanced MLOps Structure

```
MoMLNIDS/
â”œâ”€â”€ ğŸ“„ README.md                      # Top-level README (brief, points to docs/)
â”œâ”€â”€ ğŸ“‹ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“‹ requirements.in                # Dependency constraints
â”œâ”€â”€ ğŸ“‹ requirements-gpu.txt           # GPU dependencies
â”œâ”€â”€ ğŸ“‹ requirements-gpu.in            # GPU dependency constraints
â”œâ”€â”€ ğŸ”’ uv.lock                       # Locked dependencies (if using uv)
â”‚
â”œâ”€â”€ âš™ï¸ config/                        # Configuration management
â”‚   â”œâ”€â”€ default_config.yaml          # Default configuration
â”‚   â””â”€â”€ quick_test_config.yaml       # Quick test setup
â”‚
â”œâ”€â”€ ğŸ“š docs/                          # Enhanced documentation
â”‚   â”œâ”€â”€ README.md                     # Comprehensive README (this file)
â”‚   â”œâ”€â”€ ENHANCED_FEATURES.md          # Feature descriptions
â”‚   â”œâ”€â”€ PROJECT_ENHANCEMENT_SUMMARY.md # Project enhancement summary
â”‚   â”œâ”€â”€ SMOKE_TEST_SUMMARY.md         # Smoke test summary
â”‚   â””â”€â”€ UV_WORKFLOW.md                # UV workflow documentation
â”‚
â”œâ”€â”€ ğŸ”„ .github/workflows/             # CI/CD pipelines
â”‚   â”œâ”€â”€ ci.yml                        # Main CI workflow
â”‚   â””â”€â”€ enhanced-features.yml         # Enhanced features testing
â”‚
â”œâ”€â”€ ğŸ“¦ src/                           # Main source code
â”‚   â”œâ”€â”€ __init__.py                   # Python package indicator
â”‚   â”œâ”€â”€ main.py                       # Legacy: Source-only baseline
â”‚   â”œâ”€â”€ main_config.py                # âœ¨ Enhanced training with MLOps
â”‚   â”œâ”€â”€ main_improved.py              # If still needed, otherwise remove
â”‚   â”œâ”€â”€ main_pseudo.py                # Legacy: Pseudo-labeling experiments
â”‚   â”œâ”€â”€ main_pseudo_50.py             # Legacy: Extended training
â”‚   â”œâ”€â”€ manualisasi.py                # If still needed, otherwise remove
â”‚   â”œâ”€â”€ of-farneback.py               # If still needed, otherwise remove
â”‚   â”œâ”€â”€ of-lukas.py                   # If still needed, otherwise remove
â”‚   â”‚
â”‚   â”œâ”€â”€ skripsi_code/                 # Core project logic
â”‚   â”‚   â”œâ”€â”€ ğŸ§  model/                 # Neural network models
â”‚   â”‚   â”‚   â”œâ”€â”€ MoMLNIDS.py          # Main model architecture
â”‚   â”‚   â”‚   â”œâ”€â”€ FeatureExtractor.py   # Domain-invariant feature extractor
â”‚   â”‚   â”‚   â”œâ”€â”€ Classifier.py         # Label classifier
â”‚   â”‚   â”‚   â””â”€â”€ Discriminator.py      # Domain discriminator with GRL
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ¯ clustering/            # Clustering algorithms
â”‚   â”‚   â”‚   â”œâ”€â”€ cluster_methods.py    # K-means, GMM, Spectral clustering
â”‚   â”‚   â”‚   â””â”€â”€ cluster_utils.py      # Pseudo-labeling utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ› ï¸ utils/                 # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ dataloader.py         # Data loading and preprocessing
â”‚   â”‚   â”‚   â”œâ”€â”€ domain_dataset.py     # Domain-aware dataset class
â”‚   â”‚   â”‚   â”œâ”€â”€ loss.py               # Custom loss functions
â”‚   â”‚   â”‚   â””â”€â”€ utils.py              # Training utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸƒ TrainEval/             # Training and evaluation
â”‚   â”‚   â”‚   â””â”€â”€ TrainEval.py          # Training/validation loops
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ config/                # Configuration management (if specific to skripsi_code)
â”‚   â”‚   â”œâ”€â”€ ğŸ“Š experiment/            # Experiment tracking (W&B)
â”‚   â”‚   â”œâ”€â”€ ğŸ” explainability/        # Explainable AI module
â”‚   â”‚   â”œâ”€â”€ figures/                  # Figures generated by notebooks/scripts
â”‚   â”‚   â”œâ”€â”€ notebooks/                # Jupyter notebooks for exploration/analysis
â”‚   â”‚   â”œâ”€â”€ Parameters/               # Model parameters/checkpoints
â”‚   â”‚   â”œâ”€â”€ pipeline/                 # Data processing pipelines
â”‚   â”‚   â””â”€â”€ preprocessing/            # Data preprocessing scripts
â”‚   â”‚
â”‚   â””â”€â”€ utils/                        # General utility functions (if any outside skripsi_code)
â”‚
â”œâ”€â”€ ğŸ§ª tests/                         # Unit and integration tests
â”‚   â”œâ”€â”€ smoke_test.py                 # Quick functionality tests
â”‚   â”œâ”€â”€ test_imports.py               # Comprehensive import validation
â”‚   â”œâ”€â”€ test.py                       # General test cases
â”‚   â””â”€â”€ training_test.py              # Training specific tests
â”‚
â”œâ”€â”€ ğŸ“Š results/                       # Experiment outputs
â”‚   â”œâ”€â”€ experiments/                  # Experiment outputs
â”‚   â”œâ”€â”€ models/                       # Saved models
â”‚   â”œâ”€â”€ explanations/                 # XAI outputs
â”‚   â””â”€â”€ logs/                         # Training logs
â”‚
â”œâ”€â”€ ğŸ’¾ data/                          # Raw and processed data
â”‚   â””â”€â”€ parquet/                      # Preprocessed datasets
â”‚
â”œâ”€â”€ ğŸ“ˆ logs/                          # General logs
â”œâ”€â”€ ğŸ–¼ï¸ plots/                         # General plots
â”œâ”€â”€ ğŸ“¦ build/                         # Build artifacts
â”œâ”€â”€ ğŸ .venv/                         # Python virtual environment
â”œâ”€â”€ ğŸ“Š wandb/                         # Weights & Biases run data
â”œâ”€â”€ ğŸ—‘ï¸ __pycache__/                   # Python bytecode cache
â”œâ”€â”€ âš™ï¸ .aider.tags.cache.v4/          # Aider cache
â”œâ”€â”€ âš™ï¸ .git/                          # Git repository data
â”œâ”€â”€ âš™ï¸ .pytest_cache/                 # Pytest cache
â”œâ”€â”€ âš™ï¸ sk_kc/                         # Potentially redundant virtual environment
â”œâ”€â”€ âš™ï¸ skripsi_code.egg-info/         # Python package metadata
â”œâ”€â”€ âš™ï¸ skripsi_kc/                    # Potentially redundant virtual environment
â”œâ”€â”€ âš™ï¸ Training_results/              # Old training results (consider moving to results/)
â””â”€â”€ ğŸ“„ pyproject.toml                 # Project metadata and build system
```

### ğŸ†• New MLOps Features

| Component | Description | Benefits |
|-----------|-------------|----------|
| âš™ï¸ **Configuration** | YAML-based config management | Reproducible experiments, easy parameter tuning |
| ğŸ“Š **Experiment Tracking** | Weights & Biases integration | Automatic logging, comparison, collaboration |
| ğŸ” **Explainable AI** | Multiple interpretability methods | Model transparency, debugging, trust |
| ğŸ§ª **Environment Validation** | Comprehensive import testing | CI reliability, quick setup validation |
| ğŸ“š **Enhanced Documentation** | Detailed guides and references | Better onboarding, troubleshooting |
| ğŸ”„ **CI/CD Pipelines** | Automated testing workflows | Quality assurance, continuous integration |

## Training/Evaluation Cycle

### Training Process

1. **Initialization**: Model weights initialized using Xavier normal initialization
2. **Data Loading**: Source domains loaded with domain/cluster labels, target domain for testing
3. **Clustering Step**: Every `CLUSTERING_STEP` epochs, re-cluster source data using Mini-batch K-means
4. **Adversarial Training**: 
   - Forward pass through Feature Extractor
   - Label classification loss (CrossEntropy)
   - Domain discrimination loss with GRL
   - Entropy regularization for uncertainty quantification
5. **Optimization**: Separate optimizers for each component with cosine annealing scheduler

### Evaluation Metrics

- **Accuracy**: Classification accuracy on target domain
- **F1-Score**: Weighted F1-score for imbalanced classes
- **Precision/Recall**: Per-class performance metrics
- **ROC AUC**: Area Under the Receiver Operating Characteristic Curve
- **Average Precision**: Area Under the Precision-Recall Curve
- **Matthews Correlation Coefficient (MCC)**: A balanced measure for binary and multiclass classification
- **Sensitivity (Recall)**: True Positive Rate
- **Specificity**: True Negative Rate
- **Domain Classification**: Domain discrimination accuracy (training only)

All metrics are calculated using `torchmetrics` for consistency and efficiency.

### Logging and Checkpoints

- **Training Logs**: Detailed epoch-wise metrics saved to `{result_folder}/training.log`
- **Clustering Logs**: Cluster assignment changes logged to `clustering.log`
- **Model Checkpoints**: Best models saved every `SAVE_STEP` epochs
- **Results Directory**: `./ProperTraining/{target_domain}/{experiment_name}/`

## Results Directory Structure

```
ProperTraining/
â”œâ”€â”€ NF-UNSW-NB15-v2/
â”‚   â”œâ”€â”€ NF-UNSW-NB15-v2_N|PseudoLabelling|/
â”‚   â”‚   â”œâ”€â”€ training.log          # Training metrics
â”‚   â”‚   â”œâ”€â”€ clustering.log        # Clustering changes
â”‚   â”‚   â”œâ”€â”€ model_best.pth        # Best model checkpoint
â”‚   â”‚   â””â”€â”€ config.json           # Experiment configuration
â”‚   â””â”€â”€ ...
â”œâ”€â”€ NF-CSE-CIC-IDS2018-v2/
â””â”€â”€ NF-ToN-IoT-v2/
```

### Log Interpretation

**Training Log Format**:
```
Train: Epoch: 15/20 | Alpha: 0.8542 |
LClass: 0.3421 | Acc Class: 0.8901 |
LDomain: 1.2341 | Acc Domain: 0.7823 |
Loss Entropy: 0.1234 |
F1 Score: 0.8856 Precision: 0.8934 Recall: 0.8823

Test: Epoch: 15/20 |
Loss: 0.4123 | Accuracy: 0.8756 |
F1 Score: 0.8701 Precision: 0.8823 Recall: 0.8634
```

## Contributing

We welcome contributions to improve MoMLDNIDS! Please follow these guidelines:

### Development Workflow

1. **Create an Issue**: Describe the bug, feature request, or improvement
2. **Fork & Branch**: Create a feature branch from `main`
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **Implement Changes**: Follow existing code style and add tests
4. **Submit Pull Request**: Include clear description and link to issue

### Commit Message Style

Follow conventional commits format:
```
type(scope): description

feat(clustering): add spectral clustering method
fix(dataloader): resolve memory leak in batch processing
docs(readme): update installation instructions
test(model): add unit tests for feature extractor
```

### Code Style

- Follow PEP 8 for Python code formatting
- Use type hints where applicable
- Add docstrings for all public functions
- Ensure all tests pass before submitting PR



## ğŸ“š Documentation

For comprehensive documentation, guides, and tutorials, visit the [`documentation/`](./documentation/) directory:

### ğŸ¯ **Quick Start Guides**
- [`documentation/TUI_README.md`](./documentation/TUI_README.md) - Interactive textual user interface
- [`documentation/ENHANCED_DEMO_USAGE.md`](./documentation/ENHANCED_DEMO_USAGE.md) - Enhanced CLI demo script

### ğŸ” **Technical Documentation**
- [`documentation/MAIN_FUNCTIONS_SUMMARY.md`](./documentation/MAIN_FUNCTIONS_SUMMARY.md) - Complete codebase overview
- [`docs/ENHANCED_FEATURES.md`](./docs/ENHANCED_FEATURES.md) - Modern ML features and capabilities

### ğŸ“Š **Visualization & Analysis**
- [`documentation/ENHANCED_VISUALIZER_GUIDE.md`](./documentation/ENHANCED_VISUALIZER_GUIDE.md) - Advanced plotting tools
- [`documentation/RESULTS_VISUALIZER_GUIDE.md`](./documentation/RESULTS_VISUALIZER_GUIDE.md) - Standard analysis

### ğŸ“‹ **Complete Documentation Index**
- [`documentation/DOCUMENTATION_OVERVIEW.md`](./documentation/DOCUMENTATION_OVERVIEW.md) - **Meta-documentation** with navigation guide to all available documentation

## Contact Information

- **Author**: Dzaki Rafif Malik
- **Email**: malikdzaki16@gmail.com
- **Research Group**: Intelligent Systems
- **Institution**: Universitas Brawijaya

For questions, issues, or collaboration opportunities, please contact the author or create an issue in the repository.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- UNSW-NB15, CIC-IDS2018, and ToN-IoT dataset providers
- PyTorch and scikit-learn communities
- Research lab/institution support

---

**Last Updated**: January 2025
